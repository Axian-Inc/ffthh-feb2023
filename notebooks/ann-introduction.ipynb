{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How Do Machines Learn?\n",
    "\n",
    "In the last talk on machine learning, we trained a random forest classifier to classify digitized, handwritten images of digits into numerical symbols from 0 to 9.\n",
    "\n",
    "However, in that discussion, we glossed over a few important details about how these models 'learn'. \n",
    "\n",
    "## Following patterns found in nature\n",
    "\n",
    "In answering the question about how machines learn, one thing that might be helpful to ask is how people, or other biological systems, learn.\n",
    "\n",
    "A biological neuron accumulates electrical charge on the cell membranes next to the axon. The electrical charges are accumulated by action from the set of multiple presynaptic neurons that provide input to the cell.  \n",
    "\n",
    "_Neurotransmitters_ in the _synaptic cleft_ instruct the cell to open or close _ion channels_ in the neuron.  Ions travelling in or out of the cell change the the membrane potential, until a point at which an _Action potential_ is achieved, which causes electrical charge to be dissipated down the axon and towards the _postsynaptic neuron_, which starts the process anew for downstream neurons.\n",
    "\n",
    "\n",
    "<img src=\"Neuron.svg\" style=\"background-color:#fff;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron as Model\n",
    "\n",
    "If we distill the functionality of the function of a neuron into a functional unit, we can see it as a function that has several parts\n",
    "\n",
    "- an input vector representing the set of inputs from presynaptic neurons\n",
    "- a bias term representing the sensitivity of the neuron itself\n",
    "- an activation function\n",
    "\n",
    "<img src=\"modelneuron.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simplified, mathematical represenation of a neuron, used for computing, was called a _Perceptron_, and has been around for a long time (Rosenblatt, 1957)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a mathematical representation of the neuron, we can compute it \n",
    "import numpy as np\n",
    "\n",
    "example_input = [1, .2, .1, .05, .2]\n",
    "\n",
    "# these are arbitrary\n",
    "example_weights = [.2, .12, .4, .6, .90]\n",
    "\n",
    "def perceptron(input, weights, threshold):\n",
    "    \"\"\"\n",
    "    aggregates input, applying the weights, compares the aggregated input against a threshold and producing an output.\n",
    "    \"\"\"\n",
    "    input_vector = np.array(input)\n",
    "    weights = np.array(weights)\n",
    "    bias_weight = .2\n",
    "\n",
    "    # summing the activation uses the dot product\n",
    "    activation_level = np.dot(input_vector, weights) + (bias_weight * 1)                                \n",
    "    activation_level\n",
    "    \n",
    "    if activation_level >= threshold:\n",
    "        perceptron_output = 1\n",
    "    else:\n",
    "        perceptron_output = 0\n",
    "    return perceptron_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = perceptron(example_input, example_weights, 0.5)\n",
    "\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But Where's the Learning?\n",
    "\n",
    "So far, this explains a bit about how to represent a neuron mathematically, but it doesn't provide us with a lot of information about how it learns. \n",
    "\n",
    "It learns by changing the weights, based on whether the output of the system is correct or incorrect (so, in this case, it's supervised-learning).\n",
    "\n",
    "As it's supervised learning, that means that we know the answers to the question that the model is trying to solve, beforehand.  Let's add a very basic supervised learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weights(perceptron_output, \n",
    "    expected_output, \n",
    "    given_input,\n",
    "    input_weights,\n",
    "    learning_rate=1):\n",
    "    \"\"\"\n",
    "    takes observed perceptron output, and input weights, and gives a new set of weights\n",
    "    \"\"\"\n",
    "    new_weights = []\n",
    "    for i, x in enumerate(given_input):\n",
    "\n",
    "        # if the expected output is greater than the observed output, make the weight smaller\n",
    "        # if the expected output is lesser than the observed output, make the weight bigger\n",
    "        new_weight = input_weights[i] + (expected_output - perceptron_output) * x * learning_rate\n",
    "        new_weights.append(new_weight)\n",
    "    return np.array(new_weights)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the function has a \"learning rate\" parameter.  We'll come back to that in a little while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "expected_output = 0\n",
    "new_weights = adjust_weights(output, 0, example_input, example_weights)\n",
    "\n",
    "print(f'old weights are: {example_weights}')\n",
    "print(f'new weights are {new_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's put our learning algorithm and our perceptron together:\n",
    "# Remember the correct output for the the algorithm is 0\n",
    "\n",
    "output = perceptron(example_input, example_weights, 0.5)\n",
    "print(f'output before learning is {output}')\n",
    "new_weights = adjust_weights(output, 0, example_input, example_weights)\n",
    "\n",
    "output_again = perceptron(example_input, new_weights, 0.5)\n",
    "print(f'output_after_learning is {output_again}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's try to use perceptrons to do a very simple classifier task\n",
    "\n",
    "We can use a perceptron with 2 inputs and one output to try and solve a problem that trains a network to \"understand\" logical OR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example problem for learning logical OR\n",
    "\n",
    "sample_data = [[0, 0],  # False, False\n",
    "               [0, 1],  # False, True\n",
    "               [1, 0],  # True, False\n",
    "               [1, 1]]  # True, True\n",
    "\n",
    "expected_results = [0,  # (False OR False) gives False\n",
    "                    1,  # (False OR True ) gives True\n",
    "                    1,  # (True  OR False) gives True\n",
    "                    1]  # (True  OR True ) gives True\n",
    "\n",
    "activation_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "import numpy as np\n",
    "\n",
    "weights = np.random.random(2)/1000  # Small random float 0 < w < .001\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_weight = np.random.random() / 1000\n",
    "bias_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = []\n",
    "for datum in sample_data:\n",
    "    output.append(perceptron(datum, weights, activation_threshold))\n",
    "\n",
    "output_arr = np.array(output)\n",
    "for idx,datum  in enumerate(sample_data):\n",
    "    new_weights = adjust_weights(output[idx], expected_results[idx], datum, weights)\n",
    "\n",
    "new_weights\n",
    "\n",
    "# This represents one iteration, or \"batch\", of having trained our very simple nerual network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a function that represents this training.\n",
    "def train_perceptron(input_features, \n",
    "    input_labels, \n",
    "    initial_weights,\n",
    "    activation_threshold,\n",
    "    num_batches, \n",
    "    learning_rate=1):\n",
    "    \"\"\"\n",
    "    Trains a perceptron with given input\n",
    "    \"\"\"\n",
    "\n",
    "    weights = initial_weights\n",
    "    for batch_num in range(0,num_batches):\n",
    "        print(f'pre-batch weights are: {weights}')\n",
    "        output = []\n",
    "        for datum in input_features:\n",
    "            output.append(perceptron(datum, weights, activation_threshold))\n",
    "\n",
    "        for idx,datum  in enumerate(input_features):\n",
    "            weights = adjust_weights(output[idx], input_labels[idx], datum, weights,learning_rate)\n",
    "\n",
    "        print(f'post-batch weights are: {weights}, output is: {output}, expected is {input_labels}')        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's train our simple model with a few batches\n",
    "\n",
    "train_perceptron(sample_data, expected_results, weights, 0.5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do these results mean?\n",
    "\n",
    "We can see here that the simple \"network\" (which was really just one neuron) arrived at a state where it was not \"learning\" at all any more, because the network eventually got all the answers correct.\n",
    "\n",
    "In this case, our toy network converged after only one batch! Its error rate dropped to zero.\n",
    "\n",
    "When a model arrives at a point, after which it does not learn any more with the given training data set, its weights do not change. We call this _convergence_. \n",
    "\n",
    "What if we had tried a learning rate that was not the default (1)? Presumably, this would affect how many iterations it takes to reach convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_perceptron(sample_data, expected_results, weights, 0.5, 10, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, adjusting the learning rate to be lower than 1 makes the network converge more slowly.\n",
    "\n",
    "But why would you want a network to converge more slowly? Let's remember this and the other parameters that we've created for the `train_perceptron` function:  learning rate, number of batches, etc, are standard _hyperparameters_ that apply to most neural network models.  Tweaking these hyperparameters has an effect on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recapping: What did we just do?\n",
    "\n",
    "1. Start with a problem that is of a predefined dimensionality \n",
    "    - input is a vector (1x2 vector of 0 or 1) in the case of our \"logical OR\" problem\n",
    "    - output is scalar (0 or 1)\n",
    "\n",
    "2. Create a processing unit that can handle a problem that is of that dimensionality \n",
    "    - 1x2 vector of randomly initialized weights\n",
    "    - 1 bias weight \n",
    "    - a stepwise activation function \n",
    "\n",
    "3. Create a way to adjust the weights after data are processed\n",
    "    - in this case, we are taking the error output and changing the weights that contributed to the error, as defined in our `adjust_weights` function: \n",
    "    ```python\n",
    "        # if the expected output is greater than the observed output, make the weight smaller\n",
    "        # if the expected output is lesser than the observed output, make the weight bigger\n",
    "        new_weight = input_weights[i] + (expected_output - perceptron_output) * x * learning_rate\n",
    "    ```\n",
    "\n",
    "    This is one example of a _cost function_ , or _loss function_.  A neural network (or other classifier) _learns_ by optimizing a cost function so that it's at a minimum.  In the network's case, it does this by making incremental changes to the weight parameters.  \n",
    "    \n",
    "    How does this work, in more complex, less trivial networks?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some problems with Simple Perceptrons (simple neurons with stepwise or linear activation functions)\n",
    "\n",
    "\n",
    "The basic perceptron as we implemented it above is very old. In the decades between 1957 and now, there has been a lot of evolution in neural networks, but a few of the big, early problems with neural networks were as follows:\n",
    "\n",
    "1. A single Perceptron can't solve problems whose answers aren't linearly separable - that is, more complicated relationships in the patterns of data, that aren't easily delineated by a line on a chart, and aren't easily caught.\n",
    "\n",
    "2. There's no simple way to adjust the weights during learning for more than one layer of them\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of an \"XOR\" problem, which does NOT have a linearly separable solution:\n",
    "xor_features = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])\n",
    "xor_labels = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0]])\n",
    "\n",
    "train_perceptron(xor_features, xor_labels, [0.02, 0.34], 0.5, 10, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how this model does _not_ converge!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Solution to some of the early problems with neural nets:\n",
    "\n",
    "- __Add more neurons, and layers of neurons to the network__\n",
    "\n",
    "    <img src=\"Colored_neural_network.svg.png\" style=\"background-color: #fff\"/>\n",
    "\n",
    "- __Backpropagation algorithm__\n",
    "\n",
    "- Have a nonlinear activation function.  Implementing the backpropagation algorithm efficiently means being able to differentiate the activation function. Change the activation function.  The sigmoid activation function was one of the first that was adopted, and choice of the activation function, more generally, can be an important hyperparameter choice when training a model.\n",
    "\n",
    "    <img src=\"Logistic-curve.svg\" style=\"background-color: #fff\"/>\n",
    "\n",
    "    ![image](ReLU_and_GELU.svg \"Rectified and Gaussean Linear Units\")\n",
    "\n",
    "\n",
    "## End Result:\n",
    "\n",
    "The result of the choices of multiple layers of neurons, and nonlinear activation functions, is what differentiates modern neural networks from the earlier perceptrons.  The backpropagation algorithm allows for meaningful updates to multiple layers of input neurons, based on the error output.  It allows us to meaningfully change the weights of hidden layers and not just a single vector. \n",
    "\n",
    "[short video on optimizing a loss function](https://www.youtube.com/watch?v=IHZwWFHWa-w&t=310s)\n",
    "\n",
    "If this kind of iterative optimization is visualized in 3 dimensions, it can be thought Of as traversing a slope, trying to find the deepest possible 'trough', or zigzagging across a topographical map: \n",
    "\n",
    "[Some 2- and 3-d visualizations of gradient descent](https://smunix.github.io/en.wikipedia.org/wiki/Gradient_descent.html)\n",
    "\n",
    "This kind of iterative traversal of the parameter space, with the y-axis parameter being the value of the cost function (in an attempt to minimize it), is called _gradient descent_. A fully connected neural network will have converged when, on successive iterations of learning, its space on the error gradient ceases to change significantly with successive learning batches.\n",
    "\n",
    "## Revisiting a question from before\n",
    "\n",
    "Above, one of the things we asked is \"why would we want a neural network to learn more slowly\"?  \n",
    "\n",
    "- An answer is that one of the problems we sometimes see when we train ANNs is called the \"expanding gradient\" problem.  This is a problem that can occur if learning rates are set too high.  Conceptually, it means that we are \"jumping around\" the error gradient space in big leaps, rather than taking our time and traversing the gradient more slowly. This means that the steps either take us away from one of the deep minimal 'troughs' that we want to be in, or have a step size that's too large for us to make the fine-grained parameter changes we need to make to get to the bottom.\n",
    "\n",
    "- There are other permutations in gradient descent algorithms and some are more complex than others\n",
    "    - Randomization in gradient descent (Stochastic gradient descent )\n",
    "    - Manipulation of batch size and overall number of batches as hyperparameters\n",
    "    - Manipulation of the underlying loss function to be optimized.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are modern neural network APIs like? \n",
    "\n",
    "[Keras](https://keras.io/) is a layer of abstraction that provides a fluent API for building neural nets.\n",
    "\n",
    "Keras, and other machine-learning APIs, give us the ability to manipulate the kinds of hyperparameters like learning rates, and network architecture, at a high level. \n",
    "\n",
    "Below, we'll try to train a net with multiple neurons.  We'll see if we get a better result by changing the topology of our net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential                 \n",
    "from keras.layers import Dense, Activation          \n",
    "from keras.optimizers import SGD      \n",
    "\n",
    "\n",
    "# Our examples for an exclusive OR.\n",
    "x_train = np.array([[0, 0],\n",
    "                    [0, 1],\n",
    "                    [1, 0],\n",
    "                    [1, 1]])                        \n",
    "y_train = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0]])       \n",
    "\n",
    "model = Sequential()\n",
    "num_neurons = 10\n",
    "model.add(Dense(num_neurons, input_dim=2))\n",
    "model.add(Activation('tanh'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD is stochastic gradient descent, which reorganizes the order of training data and updates weights fre\n",
    "\n",
    "sgd = SGD(lr=0.1)\n",
    "model.compile(loss='binary_crossentropy', \n",
    "    optimizer=sgd,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's see if a model can learn XOR\n",
    "model.fit(x_train, y_train, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES:\n",
    "\n",
    "Several of the notes on loss functions and gradient descent, they come from [3-blue-1-brown's great video](https://www.youtube.com/watch?v=IHZwWFHWa-w) on the topic. \n",
    "\n",
    "Several of the images and code examples in this notebook are adapted from Hobson Lane et al.'s\\ text: \n",
    "\n",
    "[Natural Language Processing in Action](https://www.manning.com/books/natural-language-processing-in-action)\n",
    "\n",
    "If you are interested in NLP and machine learning in general, this is a great book.  It was written by members of Portland's own local Data Science Meetup group.\n",
    "\n",
    "### References\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Activation_function\n",
    "- Rosenblatt, 1957 [The Perceptron: A Perceiving and Recognizing Automaton](https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf)\n",
    "- Minsky and Papert, 1969 [Perceptrons: An Introduction to Computational Geometry](https://direct.mit.edu/books/book/3132/PerceptronsAn-Introduction-to-Computational)\n",
    "\n",
    "\n",
    "### Image attributions\n",
    "\n",
    "By User:Dhp1080 - &quot;Anatomy and Physiology&quot; by the US National Cancer Institute&#039;s Surveillance, Epidemiology and End Results (SEER) Program ., CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=1474927\n",
    "\n",
    "By Qef (talk) - Created from scratch with gnuplot, Public Domain, https://commons.wikimedia.org/w/index.php?curid=4310325\n",
    "\n",
    "By Ringdongdang - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=95947821\n",
    "\n",
    "Autorstwa Mayranna - Praca własna, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=30128320"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "912e0425320a54aa72daae9181d14c508cccc24d8168b9331594aaceab410339"
  },
  "kernelspec": {
   "display_name": "Python 3.8.16 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
